{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognitive Neuroscience: Group Project\n",
    "\n",
    "## Final Group Project Code Instructions\n",
    "\n",
    "Marijn van Wingerden, Department of Cognitive Science and Artificial Intelligence â€“ Tilburg University Academic Year 2020-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, you will find the programmatic instructions to complete the Group Project. \n",
    "\n",
    "You will analyse a subset of the trials and conditions from the RITA dataset, as introduced by dr. Roncaglia in the second week of class. Your time-resolved analysis, using the FFT and baseline averaging, will be performed across ALL subjects in a group (Monolinguals, Early Learners, Late Learners) in the dataset, and look for oscillatory activity in relation to the onset of the **critical item** in each sentence (the auxilary verb).\n",
    "\n",
    "You will inspect activity in the following frequency bands:\n",
    "- Delta (1-4 Hz)\n",
    "- Theta (4-8 Hz)\n",
    "- Alpha (8-12 Hz)\n",
    "- Beta (15-25 Hz)\n",
    "- low Gamma (30-60 Hz)\n",
    "- high Gamma (60-100 Hz)\n",
    "(different cutoffs points can be found in the literature, we are sticking with these for convenience)\n",
    "\n",
    "All relevant methods have been covered in Worksheets 1-7, with the exception of loading multiple datafiles. Whenever a new method/function is introduced here, it will come with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datafiles - assignment per group\n",
    "\n",
    "Each group will analyze one set of filler sentences (NA: Non-Ambiguous sentences) and a set of experimental sentences (AM: Ambiguous sentences). The conditions in the dataset are split over groups in the following way:\n",
    "\n",
    "- SF: subject-first\n",
    "- OF: object-first\n",
    "- IR: irregular rhythm\n",
    "- RR: regular rhythm\n",
    "\n",
    "- Monolinguals: RM\n",
    "    - Groups 01 + 02: SFIR triggers XX1 and XX5\n",
    "    - Groups 03 + 04: SFRR triggers XX2 and XX6\n",
    "    - Groups 05 + 06: OFIR triggers XX3 and XX7\n",
    "    - Groups 07 + 08: OFRR triggers XX4 and XX8\n",
    "- Early Learners: RB\n",
    "    - Groups 09 + 10: SFIR triggers XX1 and XX5\n",
    "    - Groups 11 + 12: SFRR triggers XX2 and XX6\n",
    "    - Groups 13 + 14: OFIR triggers XX3 and XX7\n",
    "    - Groups 15 + 16: OFRR triggers XX4 and XX8\n",
    "- Late Learners: RL\n",
    "    - Groups 17 + 18: SFIR triggers XX1 and XX5\n",
    "    - Groups 19 + 20: SFRR triggers XX2 and XX6\n",
    "    - Groups 21 + 22: OFIR triggers XX3 and XX7\n",
    "    - Groups 23 + 24: OFRR triggers XX4 and XX8\n",
    "\n",
    "- Odd groups:\n",
    "analyse the odd trials in the dataset\n",
    "- Even groups:\n",
    "analyse the even trials in the dataset\n",
    "\n",
    "You can download the datafiles from: https://surfdrive.surf.nl/files/index.php/s/JcA9speED020q4p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handing in of your code\n",
    "\n",
    "You can adapt this script template and hand it in as the code component of your Group Assignment Report.\n",
    "\n",
    "Whenever you are asked to make a plot, it should be completed with a meaningful plot title, xlabel and ylabel texts. Figures are started with a Matplotlib figure handle: \"fig_Q2A, ax = plt.subplots;\". This indicates that a link (called handle) to your figure will be saved in the variable, so we can easily check it when checking your scripts. Whenever a naming convention for a variable is given, use it, because it will allow semi-automatic grading of your project script.\n",
    "\n",
    "### Intermediate hand-in\n",
    "\n",
    "You will be able to hand in a script/notebook with your solutions to Q1-3 after the midterms, and the correct solution will be discussed in class to give you some feedback on how the Group Project is evaluated. Groups that do not hand in their solutions to Q1-3 will receive half of the total points available for these questions by default. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group members:\n",
    "\n",
    "Please list the contributors and their U-numbers here in comments:\n",
    "\n",
    "- \n",
    "-\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up: list your modules to import\n",
    "For loading/saving puroposes, we will make use of the **os** package.\n",
    "An example worksheet with instructions on how to use the os package will be provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "We will need to load the datafiles from all participants and add them all together so that we end up with a matrix that has nChannels x nTime x nParticipants (instead of trials). You can make your work easier by organising the datafiles in such a way that you put the control.npy files in their own subdirectory, and the experimental.npy files as well. \n",
    "\n",
    "In order to load the files, we can use the os package.\n",
    "\n",
    "Adapt the following so that it works on your machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "path_control = \"./group_12_control\"\n",
    "path_experimental = \"./group_12_experimental\"\n",
    "control_files = os.listdir(path_control)\n",
    "experimental_files = os.listdir(path_experimental)\n",
    "\n",
    "# check that the length of your files list matches the provided datafiles, and contains only .npy datafiles\n",
    "\n",
    "if len(control_files) and len(experimental_files) == 22:\n",
    "    print(True)\n",
    "    \n",
    "#os.listdir(path_control), os.listdir(path_experimental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data and matrix pre-allocation\n",
    "next, you will need to load these files one by one and extract the data for this participant. \n",
    "The data in the NumPy arrays are stored as Trials x Channels x Time. To aggregate across participants, you will thus need to add a 4th dimension to store the data.\n",
    "\n",
    "To be able to adequately pre-allocate the data from the different subjects, we will load one trial subject manually to have a look at the shape/dimensionality of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 64, 751)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEG = np.load(os.path.join(path_control,control_files[0])) #Right this is only loading the first guy\n",
    "              \n",
    "# control_files is a list of strings, so indexing its first element returns a string\n",
    "# in this case, we are loading the first entry of control_files, i.e. participant 1\n",
    "\n",
    "# verify that the number of trials equals 22, \n",
    "# verify that the number of channels equals 64 or 65 \n",
    "# and verify that there are 751 samples per trace\n",
    "\n",
    "np.shape(EEG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 - setting up the data structure and loading data from all participants\n",
    "\n",
    "The EEG data is currently stored as a 3-dimensional NumPy array. But to run our time-frequency analysis, we need some more information like the sampling rate and the time axis that corresponds to the stimulus-locked analysis window. In order to set up (=pre-allocate) a matrix that will hold all traces for all participants, we need to know the sizes of the dimensions of this 4-dimensional matrix, and fill up this matrix by looping over participants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 64 or 65 channels in the dataset. Only channels up to channel 59 are EEG channels\n",
    "# the remaining channels are EMG and EOG channels that we will ignore in this analysis\n",
    "# subset your EEG array so that only the EEG channels remain\n",
    "\n",
    "control = np.load(os.path.join(path_control,control_files[0]))\n",
    "control = control[:,0:59]\n",
    "np.shape(control)\n",
    "\n",
    "# There are 64 or 65 channels in the dataset. Only channels up to channel 59 are EEG channels\n",
    "# the remaining channels are EMG and EOG channels that we will ignore in this analysis\n",
    "# subset your EEG array so that only the EEG channels remain \n",
    "\n",
    "EEG = control\n",
    "\n",
    "nTrials = len(EEG[:])\n",
    "print(nTrials)\n",
    "nChans = len(EEG[0]) # number of channels\n",
    "print(nChans)\n",
    "nSamples = EEG.shape[2]\n",
    "print(nSamples)\n",
    "Parts = control_files\n",
    "nParts = len(control_files)\n",
    "print(nParts)\n",
    "\n",
    "# Define nTrials, nChans (=channels), nSamples and nParts (=participants). Then, pre-allocate a matrix\n",
    "# filled with zeros and with size nTrials x nChans x nSamples x nParticipants, one each for the control\n",
    "# and experimental data. Name them comb_data_control and comb_data_experimental\n",
    "\n",
    "comb_data_control = np.zeros((nTrials, nChans, nSamples, nParts))\n",
    "comb_data_experimental = np.zeros((nTrials, nChans, nSamples, nParts))\n",
    "\n",
    "np.shape(comb_data_control)\n",
    "\n",
    "#So here we have\n",
    "#How many times it was recorded(Trials)\n",
    "#The different nodes each measuremt was recorded from(Channels)\n",
    "#The number of samples per trace, which means per second\n",
    "\n",
    "# next, we need to loop over all participant datafiles and add them to the appropriate slice in your 4-D arrays\n",
    "# For this, you need to use specific array indexing to indicate where in comb_data_(control/experimental)\n",
    "# each participant's data needs to go. You can and should reuse the data-reading code above.\n",
    "\n",
    "# loop over participants, and wihtin each iteration of the loop, load the\n",
    "# next datafile and fill comb_data_(control/experimental) with the EEG traces (nTrials x nChans x nSamples)\n",
    "# check the shape of the matrices after filling them\n",
    "\n",
    "for ...\n",
    "    ... # caution - multiple lines of code might be needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - explore the data\n",
    "\n",
    "Let's explore this newly combined dataset a little bit. This collection of EEG traces in your dataset has been taken with a [-0.5s, 1s] window around the relevant event. What's more, each trace has been averaged to its baseline period, so that the mean amplitude should be 0 (with some rounding error). \n",
    "\n",
    "To verify, first, determine the mean for the time period of -0.5 to 0 seconds. Given that the srate = 500 Hz, the baseline period corresponds to the first 250 samples. We will work with only the control dataset (comb_data_control) in this exercise.\n",
    "- subset your combined data to only the first 250 samples\n",
    "- select a random participant and subset the data further to only this participant\n",
    "- select a random EEG channel and subset the data further to only this channel\n",
    "\n",
    "This should leave you with a nTrials x 250 (samples) matrix. Create a similar evoked matrix with the remainder of the samples. With these matrices, in a 1x3 subplot \n",
    "- plot the traces for all trials in the **baseline** matrix (use transpose if necessary).\n",
    "    - the plot should have 250 samples on the x-axis, and nTrial number of lines\n",
    "- calculate the mean for each trace (i.e., across the samples in a trace):\n",
    "    - once for the baseline period\n",
    "    - once for the remainder of the trial\n",
    "- plot these values (N of these values should be nTrials, check this) in a histogram, each in their own subplot\n",
    "\n",
    "Refer to Worksheet 1 for example uses of **np.mean**. np.std works in a similar way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean = ...\n",
    "evoked_mean = ...\n",
    "\n",
    "\n",
    "# now plot these traces and two histograms using the 1x3 subplot given\n",
    "fig_Q2A, ax = plt.subplots(figsize=(8,4), nrows=1, ncols=3) # 1x3 graph\n",
    "\n",
    "# plot the traces in ax[0]\n",
    "\n",
    "##\n",
    "## your code here\n",
    "##\n",
    "\n",
    "# plot the baseline mean in ax[1] with this code\n",
    "ax[1].hist(baseline_mean)\n",
    "plt.axes(ax[1])\n",
    "plt.title('Baseline means')\n",
    "ax[1].set_xlabel('Mean voltage')\n",
    "ax[1].set_ylabel('count')\n",
    "\n",
    "# plot the evoked mean in ax[2] with this code\n",
    "ax[2].hist(evoked_mean)\n",
    "plt.axes(ax[2])\n",
    "plt.title('Evoked means')\n",
    "ax[2].set_xlabel('Mean voltage')\n",
    "ax[2].set_ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at theses histograms, you should see that the distribution of evoked mean values can vary: while EEG recordings are referenced to a common ground, and usualy then re-referenced to the global average, we are dealing here with specific cutouts of EEG traces around specific events in the dataset. The data has been normalised to the baseline window for each trial, but the mean of the evoked part is not controlled. In addition, there might be differences in the size of the amplitudes between channels and between participants due to differences in conductivity.\n",
    "\n",
    "Illustrate that this global averaging does not guarantee equal variance. Reuse the baseline and evoked subsets:\n",
    "- Compute, instead of the mean across samples, the standard deviation (numpy.std or variants)\n",
    "- calculate the standard deviation for each trace:\n",
    "    - once for the baseline period\n",
    "    - once for the remainder of the trial\n",
    "- Adapt the plotting code for Q2A and plot these distributions of standard deviations in figure Q2B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_std = ...\n",
    "evoked_std = ...\n",
    "\n",
    "fig_Q2B, ax = plt.subplots(figsize=(8,3), nrows=1, ncols=3) # don't forget proper plot annotation\n",
    "\n",
    "##\n",
    "## your code here\n",
    "##\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 - normalizing the data\n",
    "\n",
    "So, if there are large differences in mean and/or standard deviation between channels or participants, we can implement some standard scaling. First, let think about why this \"standard scaling\" (substracting the mean, dividing by std) is important? You will be combining data from different participants for these exercises. They have been possibly recorded at different days, with different gels or electrodes, and thus with different conductivity between participants. We will assume that the recording across trials within one participant remains stable. So, in order to compare and average the recordings from different participants \"fairly\", we want them to be on more or less the same scale.\n",
    "\n",
    "We can thus attempt to normalize the signal per participant, by dividing all data per participant by its standard deviation. Let's show the extent of the problem by plotting the participants with the lowest and highest std side by side. Re-create your matrix of std values for the evoked period, but:\n",
    "- do not subset one participant, but retain all participants (still only selecting 1 channel)\n",
    "- calculate the standard deviation for each trace (across the samples dimension)\n",
    "- average the std values for each trace over trials, save in part_std \n",
    "    - you will retain one value per participant, check this\n",
    "- use np.argmax (and variants) to create two indexes, min_std and max_std that point to the participants with the lowest and highest standard deviations\n",
    "    - print the participants index min_std and max_std\n",
    "- calculate and plot the signal average over trials for these two participants, using different line colors and proper line labeling. \n",
    "    - Plot them in the first subplot of a 1x2 subplot\n",
    "- Observe the scaling difference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## your code here\n",
    "##\n",
    "\n",
    "part_std = \n",
    "min_std = \n",
    "max_std = \n",
    "\n",
    "fig_Q3, ax = plt.subplots(figsize=(8,3), ...) # don't forget proper plot annotation\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to use the standard deviation for these participants to normalize (i.e. divide) the data by this value. \n",
    "- using the selected channel matrix for these two participants as calculated above\n",
    "    - this should be a trials x timepoints matrix, per participant\n",
    "    - store as low_std_participant and high_std_participant\n",
    "- extract the standard deviation for these participant as calculated above\n",
    "- Normalize both sets traces (per participant) by the participant std\n",
    "    - save as low_std_norm and high_std_norm\n",
    "- In the second subplot, plot the **normalized** average signal over trials for these same two participants, using different line colors and proper line labeling. You can replot the figure if you want.\n",
    "    - Plot them in the second subplot of fig Q3\n",
    "    - The data should now be more or less on the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## your code here\n",
    "##\n",
    "\n",
    "low_std_part = ...\n",
    "low_std_norm = ...\n",
    "\n",
    "high_std_part = ...\n",
    "high_std_norm = ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to apply this normalization across all channels. The fairest way is to calculate the grand standard deviation per participant (over all their channels, so the relative scaling between channels remains intact). This will normalize the range of the signal within one participant, so that they will be comparable between participants. We will have to do this both for the control and the experimental dataset.\n",
    "\n",
    "In order to do this: \n",
    "- first preallocate two normalized matrices with the same size as comb_data_(control/experimental), called comb_data_norm_(control/experimental).\n",
    "- Next, create a loop to go over Participants, and inside the loop:\n",
    "    - select the data for the current participant (trials x channels x timepoints)\n",
    "        - separately for the control and experimental datasets.\n",
    "    - calculate the grand standard deviation per participant \n",
    "        - also separately for the control and experimental datasets\n",
    "    - normalization all values by this grand standard deviation\n",
    "        - Examine the numpy.std documentation to get a single std value across a 3D matrix\n",
    "    - save the normalized data per participant in the pre-allocatede normalized matrix \n",
    "        - separately for control/experimental datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## your code here\n",
    "##\n",
    "\n",
    "comb_data_norm_control = ...\n",
    "comb_data_norm_experimental = ...\n",
    "\n",
    "for ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will be plotting the raw and normalised datasets side by side to observe the differences. Before you starts, make sure you have two 4-dimensional matrices, one for the control data and one for the experimental data. Both should contain the full number of samples (e.g., baseline and evoked period). \n",
    "\n",
    "Create a 1x2 subplot, with on the left the raw data and on the right the normalised data\n",
    "- re-use part of the code in Q2 to make a subset of the baseline data\n",
    "- from this subset, select a random channel\n",
    "- for both subsetted matrices, calculate the average signal over trials \n",
    "    - this should result in a nTimepoints x nParticipants 2D matrix\n",
    "    - store as mean_baseline_raw and mean_baseline_norm\n",
    "- Then, plot this average signal over time (as in Fig Q2A) in a 1x2 subplot\n",
    "    - for the raw dataset in panel 0\n",
    "    - for the normalised dataset in panel 1\n",
    "- Save this figure as Figure1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-normalised data\n",
    "mean_baseline_raw = ...\n",
    "\n",
    "# normalised data\n",
    "mean_baseline_norm = ...\n",
    "\n",
    "# now plot the raw average traces and normalised average traces\n",
    "fig_Q3C, ax = plt.subplots(figsize=(10,4), nrows=1, ncols=2) # 1x2 graph\n",
    "\n",
    "# save Figure Q3C as your Figure 1 for your report\n",
    "Figure1 = fig_Q3C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the scaling **within** a participant (line of across-trial average signal) is not really affected, but that potential outliers **between** participants have been brought into the same scale range. \n",
    "\n",
    "We are now done with pre-processing of the data and ready to commence the spectral analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
